{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quran.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMD1tQuHxm1aI/i6s7AEo5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aSafarpoor/NLP-hw-Quran/blob/AliSa/Quran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNjUK-pIUWYU"
      },
      "source": [
        "#Start ☺"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjvdx0OvU5pj"
      },
      "source": [
        "## Question list#\n",
        "\n",
        "\n",
        "\n",
        "1.   What shoulkd we do with بسم الله الرحمن الرحیم\n",
        "2.   Output formats should change\n",
        "3.   'va' problem\n",
        "4.    khoroji 'a' 'e' 'o' etc mikhahad?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXASrVXSUe4M"
      },
      "source": [
        "# pre file and codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOZi-LGaRGm"
      },
      "source": [
        "just run first time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2OOoFiyVIli",
        "outputId": "54aea133-df80-4ad6-c56f-c8cf3c6c8ba8"
      },
      "source": [
        "% pip install camel_tools"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: camel_tools in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: camel-kenlm in /usr/local/lib/python3.7/dist-packages (from camel_tools) (2020.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.16.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from camel_tools) (4.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from camel_tools) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.19.5)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from camel_tools) (4.12.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.10.0+cu111)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.3.4)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.6.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.22.2.post1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->camel_tools) (3.10.0.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (4.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (3.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (21.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (0.1.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.2->camel_tools) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.2->camel_tools) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->camel_tools) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->camel_tools) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->camel_tools) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->camel_tools) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kBn_3SLUBgU"
      },
      "source": [
        "Below code is from https://raw.githubusercontent.com/CAMeL-Lab/camel_tools/master/camel_tools/utils/normalize.py and added here for eddition.\n",
        "\n",
        "Eddition will be describe with comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnmOd_sSaej9"
      },
      "source": [
        "### minimize block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELUdlDP-T8bE"
      },
      "source": [
        "#@title\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# MIT License\n",
        "#\n",
        "# Copyright 2018-2021 New York University Abu Dhabi\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "\n",
        "\n",
        "\"\"\"This module provides functions for normalizing Arabic text.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "from camel_tools.utils.charmap import CharMapper\n",
        "\n",
        "\n",
        "_ALEF_NORMALIZE_BW_RE = re.compile(u'[<>{|]')\n",
        "_ALEF_NORMALIZE_SAFEBW_RE = re.compile(u'[IOLM]')\n",
        "_ALEF_NORMALIZE_XMLBW_RE = re.compile(u'[IO{|]')\n",
        "_ALEF_NORMALIZE_HSB_RE = re.compile(u'[\\u0102\\u00c2\\u00c4\\u0100]')\n",
        "_ALEF_NORMALIZE_AR_RE = re.compile(u'[\\u0625\\u0623\\u0671\\u0622]')\n",
        "\n",
        "_UNICODE_CHAR_FIX = CharMapper({\n",
        "                        '\\ufdfc': 'ريال',\n",
        "                        '\\ufdfd': 'بسم الله الرحمن الرحيم',\n",
        "                    })\n",
        "\n",
        "\n",
        "def normalize_unicode(s, compatibility=True):\n",
        "    \"\"\"Normalize Unicode strings into their canonically composed form or\n",
        "    (i.e. characters that can be written as a combination of unicode characters\n",
        "    are converted to their single character form).\n",
        "\n",
        "    Note: This is essentially a call to :func:`unicodedata.normalize` with\n",
        "    form 'NFC' if **compatibility** is False or 'NFKC' if it's True.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "        compatibility (:obj:`bool`, optional): Apply compatibility\n",
        "            decomposition. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    if compatibility:\n",
        "        fixed = _UNICODE_CHAR_FIX(s)\n",
        "        return unicodedata.normalize('NFKC', fixed)\n",
        "\n",
        "    return unicodedata.normalize('NFC', s)\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_bw(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'Y', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_safebw(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a Safe Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'Y', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_xmlbw(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a XML Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'Y', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_hsb(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a Habash-Soudi-Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u00fd', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_ar(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in an Arabic string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u0649', u'\\u064a')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_bw(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'p', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_safebw(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a Safe Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'p', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_xmlbw(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a XML Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'p', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_hsb(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a Habash-Soudi-Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u0127', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_ar(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in an Arabic string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u0629', u'\\u0647')\n",
        "\n",
        "\n",
        "def normalize_alef_bw(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_BW_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_safebw(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    Safe Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_SAFEBW_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_xmlbw(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    XML Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_XMLBW_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_hsb(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    Habash-Soudi-Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_HSB_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_ar(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in an\n",
        "    Arabic string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_AR_RE.sub(u'\\u0627', s)"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq7qrLAfWwFZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxJKFovJWwqZ"
      },
      "source": [
        ""
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVhVltkJVEuj"
      },
      "source": [
        ""
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGeHK41W2Mi"
      },
      "source": [
        "# Read Quran"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDwBlMT4fV8C",
        "outputId": "9cade8b8-f4c1-4d5f-9759-f42ff7841b35"
      },
      "source": [
        "!pip install pyarabic"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.14)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWHZS_cZZ2WH"
      },
      "source": [
        "import requests\n",
        "import pyarabic.araby as araby"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VhHypUhW3vh"
      },
      "source": [
        "link = \"https://raw.githubusercontent.com/language-ml/nlp-exploring-datasets/main/religious_text/id_text_with_orthographies.txt\"\n",
        "f = requests.get(link)"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEx7sIYwXc_S"
      },
      "source": [
        "qtext = f.text\n",
        "f = \"\""
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IQVBTYZX-E_"
      },
      "source": [
        "qtext = qtext.split(\"\\n\")"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afdCILwSX_G2"
      },
      "source": [
        "qdictionary = {}\n",
        "\n",
        "for i in qtext[:-1]:\n",
        "  parted_verse = i.split(\"\\t\")\n",
        "  \n",
        "  sura_verse_num = parted_verse[0]\n",
        "  verse = parted_verse[1]\n",
        "  qdictionary[sura_verse_num] = verse[:]"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jAjlB2MY88H",
        "outputId": "844486d0-ea75-4b72-8334-a953819b5010"
      },
      "source": [
        "key_list = list((qdictionary.keys()))\n",
        "len(key_list)  "
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6236"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX8M1-p2Zj3-"
      },
      "source": [
        "def general_normalizer_1(sin):\n",
        "   s = normalize_unicode(sin)\n",
        "   s = normalize_alef_maksura_bw(s[:])\n",
        "   s = normalize_alef_maksura_safebw(s[:])\n",
        "   s = normalize_alef_maksura_xmlbw(s[:])\n",
        "   s = normalize_alef_maksura_hsb(s[:])\n",
        "   s = normalize_alef_maksura_ar(s[:])\n",
        "   s = normalize_teh_marbuta_bw(s[:])\n",
        "   s = normalize_teh_marbuta_safebw(s[:])\n",
        "   s = normalize_teh_marbuta_xmlbw(s[:])\n",
        "   s = normalize_teh_marbuta_hsb(s[:])\n",
        "   s = normalize_teh_marbuta_ar(s[:])\n",
        "   s = normalize_alef_bw(s[:])\n",
        "   s = normalize_alef_safebw(s[:])\n",
        "   s = normalize_alef_xmlbw(s[:])\n",
        "   s = normalize_alef_hsb(s[:])\n",
        "   s = normalize_alef_ar(s[:])\n",
        "   return s"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AZE9fzQ9bib9",
        "outputId": "efefd040-cb02-4e9f-8bae-2ea60cc914ec"
      },
      "source": [
        "qdictionary[key_list[4]]"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'إِيَّاكَ نَعْبُدُ وَإِيَّاكَ نَسْتَعِينُ'"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdtB9iZ8bnFk",
        "outputId": "a296ea6d-63cd-419c-80ac-72ea208d71a2"
      },
      "source": [
        "pnot_changed = 0\n",
        "\n",
        "for i in range(6236):\n",
        "  sin = qdictionary[key_list[i]]\n",
        "  sout = general_normalizer_1(qdictionary[key_list[i]])\n",
        "  qdictionary[key_list[i]] = sout\n",
        "  if sin == sout: \n",
        "    pnot_changed += 1\n",
        "print(pnot_changed , 6236-pnot_changed)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230 6006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31tcj71pcAc7"
      },
      "source": [
        "def general_normalizer_2(sin):\n",
        "  sout = araby.strip_diacritics(sin)\n",
        "  sout = sout.replace(\"   \",\" \")\n",
        "  sout = sout.replace(\"  \",\" \")\n",
        "  return sout"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshvbt-IfQOJ",
        "outputId": "97fc1f30-0146-4618-9357-18b5b2abb36f"
      },
      "source": [
        "pnot_changed = 0\n",
        "for i in range(6236):\n",
        "  sin = qdictionary[key_list[i]]\n",
        "  sout = general_normalizer_2(qdictionary[key_list[i]])\n",
        "  qdictionary[key_list[i]] = sout\n",
        "  if sin == sout: \n",
        "    pnot_changed += 1\n",
        "    \n",
        "print(pnot_changed , 6236-pnot_changed)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 6216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zomLqhFWfgsw",
        "outputId": "e4c85fa6-8c5f-461a-acf8-c2bd150063f1"
      },
      "source": [
        "for i in [1,100,1000,1435,6230]:\n",
        "  print(qdictionary[key_list[i]])\n",
        "  print(qtext[i].split(\"\\t\")[-1])\n",
        " \n",
        "  # sout = general_normalizer_2(qdictionary[key_list[i]])\n",
        "  # qdictionary[key_list[i]] = sout\n",
        "  # if sin == sout: \n",
        "    # pnot_changed += 1"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "الحمد لله رب العالمين\n",
            "الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ\n",
            "قل ان كانت لكم الدار الاخره عند الله خالصه من دون الناس فتمنوا الموت ان كنتم صادقين\n",
            "قُلْ إِنْ كَانَتْ لَكُمُ الدَّارُ الْآخِرَةُ عِنْدَ اللَّهِ خَالِصَةً مِنْ دُونِ النَّاسِ فَتَمَنَّوُا الْمَوْتَ إِنْ كُنْتُمْ صَادِقِينَ\n",
            "واذا صرفت ابصارهم تلقاء اصحاب النار قالوا ربنا لا تجعلنا مع القوم الظالمين\n",
            "وَإِذَا صُرِفَتْ أَبْصَارُهُمْ تِلْقَاءَ أَصْحَابِ النَّارِ قَالُوا رَبَّنَا لَا تَجْعَلْنَا مَعَ الْقَوْمِ الظَّالِمِينَ\n",
            "فان توليتم فما سالتكم من اجر ان اجري الا علي الله وامرت ان اكون من المسلمين\n",
            "فَإِنْ تَوَلَّيْتُمْ فَمَا سَأَلْتُكُمْ مِنْ أَجْرٍ ۖ إِنْ أَجْرِيَ إِلَّا عَلَى اللَّهِ ۖ وَأُمِرْتُ أَنْ أَكُونَ مِنَ الْمُسْلِمِينَ\n",
            "قل اعوذ برب الناس\n",
            "قُلْ أَعُوذُ بِرَبِّ النَّاسِ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RBFSGCFiBo3"
      },
      "source": [
        "save normalized file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmLJA6uHgOMw"
      },
      "source": [
        "import codecs\n",
        "\n",
        "file = codecs.open(\"normalized.txt\", \"w\", \"utf-8\")\n",
        "for i in range(6236):\n",
        "  file.write(key_list[i])\n",
        "  file.write(\"\\t\")\n",
        "  file.write(qdictionary[key_list[i]])\n",
        "  file.write(\"\\n\")\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdETN-4VkpUN"
      },
      "source": [
        "# phase 1\n",
        "## creating token bag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5g3kD7Th5dn"
      },
      "source": [
        "# qdictionary"
      ],
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poWzugaYk9k8"
      },
      "source": [
        "bi_token_bag = {}\n",
        "list_dk = list(qdictionary.keys())\n",
        "for i in range(len(qdictionary)):\n",
        "  k_name = list_dk[i]\n",
        "  verse = qdictionary[k_name]\n",
        "  \n",
        "  temp = verse.split(\" \")\n",
        "  for i in range(len(temp)-1):\n",
        "      try:\n",
        "        bi_token_bag[temp[i] + \" \" + temp[i+1]].append(k_name)\n",
        "      except:\n",
        "        bi_token_bag[temp[i] + \" \" + temp[i+1]] = [k_name]"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7egCMZn_lTT7",
        "outputId": "8d4c250d-5ae6-40e3-c8f5-1c7d5e38554e"
      },
      "source": [
        "bi_token_list = list(bi_token_bag.keys())\n",
        "print(len(bi_token_list))"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b9328qElUyz",
        "outputId": "1cbbd505-7c28-4d50-ff9d-408a32ad41cf"
      },
      "source": [
        "for i in range(10):\n",
        "  print(bi_token_list[i] , \":::\" , bi_token_bag[bi_token_list[i]])"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "بسم الله ::: ['1##1', '11##41', '27##30']\n",
            "الله الرحمن ::: ['1##1', '27##30']\n",
            "الرحمن الرحيم ::: ['1##1', '1##3', '2##163', '27##30', '41##2', '59##22']\n",
            "الحمد لله ::: ['1##2', '6##1', '7##43', '10##10', '14##39', '16##75', '17##111', '18##1', '23##28', '27##15', '27##59', '27##93', '29##63', '31##25', '34##1', '35##1', '35##34', '39##29', '39##74', '39##75', '40##65']\n",
            "لله رب ::: ['1##2', '6##45', '6##162', '10##10', '27##44', '37##182', '39##75', '40##65']\n",
            "رب العالمين ::: ['1##2', '5##28', '6##45', '6##162', '7##54', '7##61', '7##67', '7##104', '10##10', '10##37', '26##16', '26##23', '26##77', '26##109', '26##127', '26##145', '26##164', '26##180', '26##192', '27##8', '27##44', '28##30', '32##2', '37##182', '39##75', '40##64', '40##65', '41##9', '43##46', '45##36', '56##80', '59##16', '69##43', '81##29']\n",
            "مالك يوم ::: ['1##4']\n",
            "يوم الدين ::: ['1##4', '15##35', '26##82', '37##20', '38##78', '51##12', '56##56', '82##15', '82##17', '82##18']\n",
            "اياك نعبد ::: ['1##5']\n",
            "نعبد واياك ::: ['1##5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFnQtuBCqwZ4"
      },
      "source": [
        "draw hist for fun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuvMxc7oqaPg"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counter_list = np.zeros(43685)"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qe7cy-lq6cm"
      },
      "source": [
        "x = []\n",
        "for i in range(43685):\n",
        "   counter_list[i] = len( bi_token_bag[bi_token_list[i]])\n",
        "   if len( bi_token_bag[bi_token_list[i]]) > 50:\n",
        "     x.append([len( bi_token_bag[bi_token_list[i]]) , bi_token_list[i]])"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MAjx9DerKTH",
        "outputId": "a49d80df-d83e-494a-813d-a4de228152a1"
      },
      "source": [
        "int(max(counter_list))"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_ZASIk6r7Cu"
      },
      "source": [
        "x.sort()"
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUnvumy4sh_W",
        "outputId": "90894577-4bfb-4adc-f5a6-489420bb9a68"
      },
      "source": [
        "x[::-1]"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[257, 'ان الله'],\n",
              " [184, 'الذين امنوا'],\n",
              " [176, 'في الارض'],\n",
              " [142, 'يا ايها'],\n",
              " [134, 'الذين كفروا'],\n",
              " [133, 'السماوات والارض'],\n",
              " [92, 'من قبل'],\n",
              " [92, 'ايها الذين'],\n",
              " [89, 'من الله'],\n",
              " [87, 'كل شيء'],\n",
              " [84, 'من بعد'],\n",
              " [84, 'ان الذين'],\n",
              " [83, 'من دون'],\n",
              " [81, 'ان كنتم'],\n",
              " [72, 'علي الله'],\n",
              " [72, 'دون الله'],\n",
              " [71, 'في السماوات'],\n",
              " [71, 'الله من'],\n",
              " [71, 'الله ان'],\n",
              " [69, 'ما في'],\n",
              " [69, 'سبيل الله'],\n",
              " [63, 'الله لا'],\n",
              " [62, 'من يشاء'],\n",
              " [61, 'عند الله'],\n",
              " [61, 'الحياه الدنيا'],\n",
              " [61, 'الا ان'],\n",
              " [60, 'يوم القيامه'],\n",
              " [57, 'ان في'],\n",
              " [56, 'علي كل'],\n",
              " [53, 'وعملوا الصالحات'],\n",
              " [53, 'ما كانوا'],\n",
              " [52, 'في ذلك'],\n",
              " [51, 'وما كان'],\n",
              " [51, 'من السماء']]"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93XxbJaXsjkm"
      },
      "source": [
        "input = \"آیه را زیر لب زمزمه می‌کرد که أَمْ حَسِبْتَ أَنَّ أَصْحَبَ ٱلْكَهْفِ وَٱلرَّقِيمِ كَانُواْ مِنْ ءَايَتِنَا عَجَبًا، آیا اصحاب کهف را از عجایب آیات ما می‌پنداری؟ پرواز\""
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIPcVKxtRu9"
      },
      "source": [
        "def input_normalizer(input):\n",
        "  for i in \"?!.؟!.\":\n",
        "    input = input.replace(i , \"\")\n",
        "  normalized_in_1 = general_normalizer_1(input)\n",
        "  normalized_in_2 = general_normalizer_2(normalized_in_1)\n",
        "\n",
        "  return normalized_in_2"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYNJc5uMtfOV"
      },
      "source": [
        "bad_alphabets = ['\\u200c' , 'پ' ,  'ژ' , 'چ' , 'گ']"
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg3ZSGjjt-qF"
      },
      "source": [
        "input = input_normalizer(input)\n",
        "inlist = input.split(\" \")\n",
        "bag_of_input = []\n",
        "for i in range(len(inlist)-1):\n",
        "  flag = True\n",
        "  for alphabet in bad_alphabets: \n",
        "    if alphabet in inlist[i] or alphabet in inlist[i+1]:\n",
        "      flag = False\n",
        "  if flag:\n",
        "    bag_of_input.append(inlist[i] + \" \" + inlist[i+1])"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tixSCOm3uEGN",
        "outputId": "bde99a82-6400-4cd4-8284-59d6bd55fa84"
      },
      "source": [
        "bag_of_input"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ایه را',\n",
              " 'را زیر',\n",
              " 'زیر لب',\n",
              " 'لب زمزمه',\n",
              " 'که ام',\n",
              " 'ام حسبت',\n",
              " 'حسبت ان',\n",
              " 'ان اصحب',\n",
              " 'اصحب الكهف',\n",
              " 'الكهف والرقيم',\n",
              " 'والرقيم كانوا',\n",
              " 'كانوا من',\n",
              " 'من ءايتنا',\n",
              " 'ءايتنا عجبا،',\n",
              " 'عجبا، ایا',\n",
              " 'ایا اصحاب',\n",
              " 'اصحاب کهف',\n",
              " 'کهف را',\n",
              " 'را از',\n",
              " 'از عجایب',\n",
              " 'عجایب ایات',\n",
              " 'ایات ما']"
            ]
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yBP6zWeywZB"
      },
      "source": [
        "# phase 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwft5ixSvPmz"
      },
      "source": [
        "import re"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkhQfAP6y5h4"
      },
      "source": [
        "list_bi_token_bag = list(bi_token_bag.keys())\n",
        "found_list = []\n",
        "for biword in bag_of_input:\n",
        "  if biword in list_bi_token_bag:\n",
        "    found_list.append([biword , bi_token_bag[biword]])\n"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6mWbgmSy66B",
        "outputId": "bf79b91f-ba7a-4dee-aecd-d05bf2f146f3"
      },
      "source": [
        "found_list"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ام حسبت', ['18##9']],\n",
              " ['حسبت ان', ['18##9']],\n",
              " ['الكهف والرقيم', ['18##9']],\n",
              " ['والرقيم كانوا', ['18##9']],\n",
              " ['كانوا من', ['3##164', '18##9', '30##49', '40##21', '62##2', '83##29']]]"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xC26lIGH0lJH",
        "outputId": "6f69dd2c-da08-4810-e6ed-5baa54ef64d2"
      },
      "source": [
        "found_list[1][0]"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'حسبت ان'"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZcqSUrK0uh3",
        "outputId": "175a564b-f831-44c9-af80-b79839af27d0"
      },
      "source": [
        "found_list[1][1]"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['18##9']"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7wEt3lcQ0xPP",
        "outputId": "d06c9b14-f31b-4ef1-9b50-177bc8cf22a6"
      },
      "source": [
        "qdictionary['18##9']"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ام حسبت ان اصحاب الكهف والرقيم كانوا من اياتنا عجبا'"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ_59s3P120H"
      },
      "source": [
        "def check_similarity(biword , input_sentence , verse):\n",
        "   biword_extra = \".*\" + biword + \".*\"\n",
        "   input_cases = re.findall(biword_extra , verse)\n",
        "   print(input_cases)"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj73CuhF0-ue",
        "outputId": "67c3ce18-3559-43c1-872e-70d20e5980c2"
      },
      "source": [
        "for sample in found_list:\n",
        "  biword = sample[0]\n",
        "  for address in sample[1]:\n",
        "    out = check_similarity(biword , input_sentence = input , verse = qdictionary[address])  \n",
        "    "
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ام حسبت ان اصحاب الكهف والرقيم كانوا من اياتنا عجبا']\n",
            "['ام حسبت ان اصحاب الكهف والرقيم كانوا من اياتنا عجبا']\n",
            "['ام حسبت ان اصحاب الكهف والرقيم كانوا من اياتنا عجبا']\n",
            "['ام حسبت ان اصحاب الكهف والرقيم كانوا من اياتنا عجبا']\n",
            "['لقد من الله علي المؤمنين اذ بعث فيهم رسولا من انفسهم يتلو عليهم اياته ويزكيهم ويعلمهم الكتاب والحكمه وان كانوا من قبل لفي ضلال مبين']\n",
            "['ام حسبت ان اصحاب الكهف والرقيم كانوا من اياتنا عجبا']\n",
            "['وان كانوا من قبل ان ينزل عليهم من قبله لمبلسين']\n",
            "['اولم يسيروا في الارض فينظروا كيف كان عاقبه الذين كانوا من قبلهم كانوا هم اشد منهم قوه واثارا في الارض فاخذهم الله بذنوبهم وما كان لهم من الله من واق']\n",
            "['هو الذي بعث في الاميين رسولا منهم يتلو عليهم اياته ويزكيهم ويعلمهم الكتاب والحكمه وان كانوا من قبل لفي ضلال مبين']\n",
            "['ان الذين اجرموا كانوا من الذين امنوا يضحكون']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S5x9xBe2AH9",
        "outputId": "b287b3ea-ce09-40e7-9209-4deb608990e5"
      },
      "source": [
        "# re.findall(\".as\", \"asdassas\" )"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['das', 'sas']"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtnyG2CN2KL2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}